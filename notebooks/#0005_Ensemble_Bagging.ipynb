{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "#0005_Ensemble_Bagging.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTAM9bg50fam"
      },
      "source": [
        "# Ensemble Learning through Bagging \n",
        "\n",
        "**bagging == Bootstrapping Aggregation** \n",
        "\n",
        "$\\implies$  hyperparam = {M = #learners, alpha = # relative trainset size}\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-19T19:33:18.394937Z",
          "start_time": "2020-11-19T19:33:17.042552Z"
        },
        "id": "dG7lVo470fam",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3663f130-4c68-42fa-87a6-79f193997185"
      },
      "source": [
        "!git clone https://github.com/tlpss/ML-Project2.git\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.gaussian_process.kernels import RBF, WhiteKernel\n",
        "\n",
        "# add project root folder to path to allow import local modules\n",
        "import os\n",
        "import sys\n",
        "sys.path.append(os.path.abspath(os.path.join('./ML-Project2')))\n",
        "\n",
        "module_path = os.path.abspath(os.path.join('..'))\n",
        "if module_path not in sys.path:\n",
        "    sys.path.append(module_path)\n",
        "# import local modules\n",
        "from stochastic_models import *\n",
        "from visualisations import *\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ML-Project2'...\n",
            "remote: Enumerating objects: 454, done.\u001b[K\n",
            "remote: Counting objects: 100% (454/454), done.\u001b[K\n",
            "remote: Compressing objects: 100% (315/315), done.\u001b[K\n",
            "remote: Total 454 (delta 263), reused 295 (delta 124), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (454/454), 1.48 MiB | 19.74 MiB/s, done.\n",
            "Resolving deltas: 100% (263/263), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-14T11:40:28.368547Z",
          "start_time": "2020-11-14T11:40:28.365554Z"
        },
        "id": "piWP2Y710fam"
      },
      "source": [
        "## Parameter Configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-19T19:33:18.399924Z",
          "start_time": "2020-11-19T19:33:18.395934Z"
        },
        "id": "QVy6iI6f0fam"
      },
      "source": [
        "np.random.seed(2020)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-19T19:33:18.404911Z",
          "start_time": "2020-11-19T19:33:18.400921Z"
        },
        "id": "VgF1gYSZ0fam"
      },
      "source": [
        "N_train = 5000\n",
        "N_test = 50000\n",
        "d = 1\n",
        "T = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-19T19:33:18.411892Z",
          "start_time": "2020-11-19T19:33:18.406906Z"
        },
        "id": "auFqti170fam"
      },
      "source": [
        "lambda_range = (N_train*1e-9 , N_train*1e-3)\n",
        "alpha_range = (8.3*1e-5, 0.83)\n",
        "length_scale = np.sort(1/np.sqrt((2*alpha_range[0], 2*alpha_range[1])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-14T11:40:29.811046Z",
          "start_time": "2020-11-14T11:40:29.808054Z"
        },
        "id": "Ibn03cnz0fam"
      },
      "source": [
        "## Create Kernel & prepare datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-19T19:33:18.417877Z",
          "start_time": "2020-11-19T19:33:18.412889Z"
        },
        "id": "wjD-Ur7D0fam"
      },
      "source": [
        "#kernel\n",
        "kernel = RBF(length_scale= (length_scale[0] + length_scale[1])/2, length_scale_bounds=length_scale) \\\n",
        "        + WhiteKernel(noise_level= (lambda_range[0] + lambda_range[1])/2 , noise_level_bounds=lambda_range)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-19T19:33:18.432836Z",
          "start_time": "2020-11-19T19:33:18.418874Z"
        },
        "id": "eV0D444n0fan"
      },
      "source": [
        "#generate drivers\n",
        "s_train = MaxCallStochasticModel(N_train,d,[1/12,11/12])\n",
        "s_train.generate_samples()\n",
        "s_test = MaxCallStochasticModel(N_test, d, [1/12,11/12])\n",
        "s_test.generate_samples()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-19T19:33:18.441812Z",
          "start_time": "2020-11-19T19:33:18.433833Z"
        },
        "id": "mZu9AViu0fan"
      },
      "source": [
        "#prepare datasets & values\n",
        "y_train = s_train.y\n",
        "X_train = s_train.X\n",
        "S_train = s_train.S\n",
        "\n",
        "y_test = s_test.y\n",
        "X_test = s_test.X\n",
        "S_test = s_test.S\n",
        "\n",
        "V_T = y_test  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "robWrT8JyG5d"
      },
      "source": [
        "## calculate V_0 separately using bigger dataset\n",
        "s_v =MaxCallStochasticModel(200000, d, [1/12,11/12])\n",
        "s_v.generate_samples()\n",
        "V_0 = s_v.generate_true_V(0)\n",
        "\n",
        "V_0= V_0.mean()\n",
        "V_0 # Average expected PROFIT!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-19T19:33:18.447798Z",
          "start_time": "2020-11-19T19:33:18.443808Z"
        },
        "id": "CDNrXA_P0fan"
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-14T11:40:33.048462Z",
          "start_time": "2020-11-14T11:40:33.045471Z"
        },
        "id": "k832NbtC0fao"
      },
      "source": [
        "## Create Custom Models\n",
        "(to have more control of splitting etc)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-19T19:33:18.456772Z",
          "start_time": "2020-11-19T19:33:18.449791Z"
        },
        "id": "OcPQ76n_0fao"
      },
      "source": [
        "from aggregating.models import SimpleBagger\n",
        "s = SimpleBagger(11,0.5,None)\n",
        "s.get_params()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqONM3sj0fao"
      },
      "source": [
        "## GridSearch\n",
        "\n",
        "nB: cannot use Scikit gridsearch as it performs CV and we want to have a different test set of a larger size!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-15T17:27:39.347302Z",
          "start_time": "2020-11-15T17:27:39.344239Z"
        },
        "id": "a2BFgvcD0fao",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2de14480-1273-4fed-85ca-91b80c8a3f24"
      },
      "source": [
        "#reference:\n",
        "from aggregating.gridsearch import create_logger, evaluate_model\n",
        "from aggregating.utils import flatten_X\n",
        "\n",
        "hyperparams= {'M':1, 'train_size_alpha':1.0} #baseline!\n",
        "model = GaussianProcessRegressor(kernel)\n",
        "reference_error = evaluate_model(model,hyperparams,flatten_X(X_train),y_train,1, [1/12,11/12],5,N_test,MaxCallStochasticModel,V_0)\n",
        "print(reference_error)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " {'M': 1, 'train_size_alpha': 1.0} -> thread id = 140363136583552\n",
            "{'M': 1, 'train_size_alpha': 1.0} , 0 -> 0.1438355169296338\n",
            "{'M': 1, 'train_size_alpha': 1.0} , 1 -> 0.17310338400870004\n",
            "{'M': 1, 'train_size_alpha': 1.0} , 2 -> 0.12835492187083933\n",
            "{'M': 1, 'train_size_alpha': 1.0} , 3 -> 0.14720125953904917\n",
            "{'M': 1, 'train_size_alpha': 1.0} , 4 -> 0.11411198863413166\n",
            "{'M': 1, 'train_size_alpha': 1.0} -> [0.1438355169296338, 0.17310338400870004, 0.12835492187083933, 0.14720125953904917, 0.11411198863413166]\n",
            "[0.1438355169296338, 0.17310338400870004, 0.12835492187083933, 0.14720125953904917, 0.11411198863413166]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jeiJMQMezlk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18032256-e40f-474d-f0bb-84648d40e066"
      },
      "source": [
        "reference_error_mean = sum(reference_error)/len(reference_error)\n",
        "print(reference_error_mean)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.1413214141964708\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2020-11-19T19:33:17.063Z"
        },
        "id": "AlUGmpIc0fao",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 584
        },
        "outputId": "34dd4879-e1f9-434b-e7ad-2a2c5a43c07c"
      },
      "source": [
        "from multiprocessing import  cpu_count,current_process\n",
        "from multiprocessing.pool import ThreadPool\n",
        "import functools\n",
        "import threading\n",
        "\n",
        "from aggregating.gridsearch import create_logger, evaluate_model\n",
        "from aggregating.utils import flatten_X\n",
        "\n",
        "# GRIDSEARCH PARAMS\n",
        "model = SimpleBagger(0,0,GaussianProcessRegressor(kernel,copy_X_train=False))\n",
        "trials = 3\n",
        "M_grid = [1,3,5,7,9]\n",
        "alpha_grid = [0.2,0.3,0.4,0.5]\n",
        "results = []\n",
        "print(cpu_count())\n",
        "### ACTUAL GRIDSEARCH\n",
        "pool = ThreadPool(cpu_count()) \n",
        "for m in M_grid:\n",
        "    for alpha in alpha_grid:\n",
        "        hyperparams= {'M':m, 'train_size_alpha':alpha}\n",
        "        pool.apply_async(evaluate_model, args=(model,hyperparams,flatten_X(X_train),y_train,1, [1/12,11/12],trials,N_test,MaxCallStochasticModel,V_0,None,[2020,2021,2022]),callback = create_logger(hyperparams,results))\n",
        "pool.close()\n",
        "pool.join()\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n",
            " {'M': 1, 'train_size_alpha': 0.2} -> thread id = 140362423404288\n",
            "fit\n",
            "(5000, 2)\n",
            " {'M': 1, 'train_size_alpha': 0.3} -> thread id = 140362415011584\n",
            "fit\n",
            "(5000, 2)\n",
            "predict\n",
            "(50000, 2)\n",
            "predict\n",
            "(50000, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-1f0b0770994b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhyperparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mflatten_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mN_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mMaxCallStochasticModel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mV_0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2020\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2021\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2022\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_logger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyperparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'joining pool'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mCLOSE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTERMINATE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_worker_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    547\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1070\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1072\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1073\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2020-11-19T19:33:17.065Z"
        },
        "id": "DBdsjTDM0fao"
      },
      "source": [
        "converted_results = np.ones((len(M_grid),len(alpha_grid),trials))*(-1)\n",
        "for item in results:\n",
        "    print(item)\n",
        "    converted_results[M_grid.index(item[0]),alpha_grid.index(item[1])] = item[2]\n",
        "\n",
        "print(converted_results.shape)\n",
        "print(converted_results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2020-11-19T19:33:17.068Z"
        },
        "id": "rPHgBIns0fao"
      },
      "source": [
        "masked_results= np.ma.masked_where(converted_results <= 0.0,converted_results) # some runs have been aborted every now and then -> filter them out\n",
        "means = masked_results.mean(axis=2)\n",
        "sigmas = masked_results.std(axis=2)\n",
        "means.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2020-11-19T19:33:17.070Z"
        },
        "id": "sGxPSAhY0fao"
      },
      "source": [
        "plt.hlines(reference_error_mean,xmin=M_grid[0],xmax=M_grid[-1],linestyles='dashed',label=\"reference error\")\n",
        "for i in range(len(alpha_grid)):\n",
        "    plt.errorbar(np.array(M_grid),means[:,i],sigmas[:,i],marker ='o',label = f\"alpha = {alpha_grid[i]}\")\n",
        "plt.title(f\"Bagging Normalized error: N_train = {N_train}, d= {d}, N_test= {N_test}\")\n",
        "plt.xlabel(\"M\")\n",
        "plt.xticks(M_grid)\n",
        "plt.ylabel(\"normalized error\")\n",
        "plt.legend(loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7Welij90fao"
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-15T17:54:08.608678Z",
          "start_time": "2020-11-15T17:54:08.603664Z"
        },
        "id": "1rzYa8Tb0fao"
      },
      "source": [
        "## Store results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2020-11-19T19:33:17.072Z"
        },
        "id": "D6CwhCiR0fao"
      },
      "source": [
        "res_dict = {'N_train': N_train, 'N_test': N_test,'mgrid': M_grid, 'alpha_grid': alpha_grid, 'errors': converted_results.tolist()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "start_time": "2020-11-19T19:33:17.075Z"
        },
        "id": "tizPo21G0fao"
      },
      "source": [
        "import json\n",
        "import datetime\n",
        "with open(f'#0005_hard_bagging_{str(datetime.date.today())}.json', 'w') as fp:\n",
        "    json.dump(res_dict, fp)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}